{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c99b800-422a-4631-9b0f-192eefab4c6d",
   "metadata": {},
   "source": [
    "# Survival with MNIST\n",
    "\n",
    "In this example, we will use the `PyTorch` lightning framework to further show how easy is it to use `TorchSurv`\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "To run this notebooks, dependencies must be installed. the recommended method is to use our development conda environment (**preferred**). Instruction can be found [here](https://opensource.nibr.com/torchsurv/devnotes.html#set-up-a-development-environment-via-conda) to install all optional dependencies. The other method is to install only required packages using the command line below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31df87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install only required packages (optional)\n",
    "# %pip install lightning\n",
    "# %pip install matplotlib\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac2861e-9c15-4ab6-85b0-f8120a07119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/corolth1/anaconda3/envs/torchsurv/lib/python3.11/site-packages/lightning/fabric/__init__.py:40: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "/Users/corolth1/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/corolth1/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <85A36C65-3F71-3C3B-B529-961AE17DBE73> /Users/corolth1/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <6B8AC17B-04CC-36D0-BD01-780381EFB0CC> /Users/corolth1/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import lightning as L\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import v2\n",
    "from torchsurv.loss.cox import neg_partial_log_likelihood\n",
    "from torchsurv.loss.momentum import Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c14ecf-33f2-4b48-bc94-db582e02bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch boilerplate - see https://github.com/Novartis/torchsurv/blob/main/docs/notebooks/helpers_momentum.py\n",
    "from helpers_momentum import MNISTDataModule, LitMomentum, LitMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307fea5f-9a28-4258-90ea-05c3793d5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc09dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "_ = seed_everything(123, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebaf967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPU/TPU is available.\n"
     ]
    }
   ],
   "source": [
    "# Detect available accelerator; Downgrade batch size if only CPU available\n",
    "if any([torch.cuda.is_available(), torch.backends.mps.is_available()]):\n",
    "    print(\"CUDA-enabled GPU/TPU is available.\")\n",
    "    BATCH_SIZE = 500  # batch size for training\n",
    "else:\n",
    "    print(\"No CUDA-enabled GPU found, using CPU.\")\n",
    "    BATCH_SIZE = 50  # batch size for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794004c5-588c-4590-ae96-c6d9e52109ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2  # number of epochs to train\n",
    "FAST_DEV_RUN = None  # Quick prototype, comment line for full epochs training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ac482",
   "metadata": {},
   "source": [
    "## Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72435795",
   "metadata": {},
   "source": [
    "For this experiment, here's are our assumptions:\n",
    "* We are using the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) as inputs. \n",
    "* The **observed digits becomes the time to event** (e.g., the picture of a nine becomes time=9).\n",
    "* To prevent log(0) issue, all zeros are transformed as tens (**time 0 -> 10**)\n",
    "* All samples experienced an event (**no censoring**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abbc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms our images\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize(224, antialias=True),\n",
    "        v2.Normalize(mean=(0,), std=(1,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf5caff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Error #15: Initializing libomp.dylib, but found libomp.dylib already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://openmp.llvm.org/\n",
      "OMP: Error #15: Initializing libomp.dylib, but found libomp.dylib already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://openmp.llvm.org/\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 40486) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1284\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/multiprocessing/connection.py:948\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 40486) is killed by signal: Abort trap: 6. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m datamodule\u001b[38;5;241m.\u001b[39msetup()  \u001b[38;5;66;03m# Wrangle the data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print image examples, with label\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1491\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1491\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1453\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1453\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1455\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/torchsurv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1297\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1296\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 40486) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Load datamodule\n",
    "datamodule = MNISTDataModule(batch_size=BATCH_SIZE, transforms=transforms)\n",
    "datamodule.prepare_data()  # Download the data\n",
    "datamodule.setup()  # Wrangle the data\n",
    "\n",
    "# print image examples, with label\n",
    "x, y = next(iter(datamodule.train_dataloader()))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [13, 5]\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(x[i].squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"time: {y[i]}, event = 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d28cbc-89df-428f-bb6a-a313696ebddf",
   "metadata": {},
   "source": [
    "## Setup model backbone\n",
    "\n",
    "First we need to define out model backbone. We will use the [resnet18](https://pytorch.org/hub/pytorch_vision_resnet/) model, without pretrained weights. We change two aspect of the model to fit our experiment:\n",
    "\n",
    "* Changed the first convolution layer to **fit our grayscale images**\n",
    "* Changed the last dense layer to output a single value (here `log hazard`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c216fa33-de09-4be2-82cc-83cb73db3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=None)\n",
    "# Fits grayscale images\n",
    "resnet.conv1 = torch.nn.Conv2d(\n",
    "    1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    ")\n",
    "# Output log hazards\n",
    "resnet.fc = torch.nn.Linear(in_features=resnet.fc.in_features, out_features=1)\n",
    "\n",
    "# Compile model\n",
    "# resnet = torch.compile(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056a675-fbce-4f4b-86c0-ab7dd924e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "x = torch.randn((6, 1, 28, 28))  # Example batch of 6 MNIST images\n",
    "print(f\"{transforms(x).shape}\")  # Check input dimension\n",
    "print(f\"{resnet(transforms(x)).shape}\")  # Check output dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948492c-3e2a-405e-b239-cbb4483b50b8",
   "metadata": {},
   "source": [
    "## Regular model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439740a",
   "metadata": {},
   "source": [
    "For this experiment, we are using the trainer from [pytorch lightning](https://lightning.ai/docs/pytorch/2.1.3/starter/introduction.html). Most of the boilerplate code is under the hood, so we can focus on the ease of using the `TorchSurv` loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a2c7e-a1ef-42fa-ba74-1d33a1dcf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train first model (regular training) using our backbone\n",
    "model_regular = LitMNIST(backbone=copy.deepcopy(resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f577acf-a821-41a4-8544-318617755d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",  # Use best accelerator\n",
    "    logger=False,  # No logging\n",
    "    enable_checkpointing=False,  # No model checkpointing\n",
    "    limit_train_batches=0.1,  # Train on 10% of data\n",
    "    max_epochs=EPOCHS,  # Train for EPOCHS\n",
    "    fast_dev_run=FAST_DEV_RUN,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430079cc-4fad-4da2-8ea5-aa904c41ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "trainer.fit(model_regular, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854deb3-52f8-4a92-b38f-ff304bf82a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "trainer.test(model_regular, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4efafc-e731-423c-8d1d-5b5fabf573da",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "For the the last part of the experiment, we are using the **same backbone model**, but now using a momentum loss. This loss allows to use previously computed batch value to increasing the effective loss samples. Details can be found [here](https://opensource.nibr.com/torchsurv/_autosummary/torchsurv.loss.momentum.html#module-torchsurv.loss.momentum).\n",
    "\n",
    "The idea behind is fairly simple and inspired from [MoCo](https://arxiv.org/abs/1911.05722) to fit into a survival analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab50a3f-5670-4264-b2c0-4eccb5f48624",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTOR = 10  # Number of batch to keep in memory. Increase our training batch size artificially by factor of 10 here\n",
    "resnet_momentum = Momentum(\n",
    "    copy.deepcopy(resnet), neg_partial_log_likelihood, steps=FACTOR, rate=0.999\n",
    ")\n",
    "model_momentum = LitMomentum(backbone=resnet_momentum)\n",
    "\n",
    "# By using momentum, we can in theory reduce our batch size by factor and still have the same effective sample size\n",
    "datamodule_momentum = MNISTDataModule(\n",
    "    batch_size=BATCH_SIZE // FACTOR, transforms=transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00473ec0-9f44-47f2-824d-02dcc92dba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",  # Use best accelerator\n",
    "    logger=False,  # No logging\n",
    "    enable_checkpointing=False,  # No model checkpointing\n",
    "    limit_train_batches=0.1,  # Train on 10% of data\n",
    "    max_epochs=EPOCHS,  # Train for EPOCHS\n",
    "    fast_dev_run=FAST_DEV_RUN,\n",
    "    deterministic=True,\n",
    ")\n",
    "# Fit the model\n",
    "trainer.fit(model_momentum, datamodule_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441c1ea-b87f-4ff7-92dd-a8d7abf8daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "trainer.test(model_momentum, datamodule_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311c310",
   "metadata": {},
   "source": [
    "## Let's compare the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup metics for each model\n",
    "from torchsurv.metrics.cindex import ConcordanceIndex\n",
    "\n",
    "cindex1 = ConcordanceIndex()  # Regular model\n",
    "cindex2 = ConcordanceIndex()  # Momentum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infere log hazards on unseen batch from test data\n",
    "model_regular.eval()\n",
    "model_momentum.eval()\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(datamodule.test_dataloader()))\n",
    "    y[y == 0] = 10\n",
    "    log_hz1 = model_regular(x)\n",
    "    # For momentum, we advice to use the target network for inteference\n",
    "    log_hz2 = model_momentum.model.target(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe05aec",
   "metadata": {},
   "source": [
    "Despite training with batches 10x smaller than the regular model, the momentum model is performing better than the regular model on the same test batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cindex (regular)  = {cindex1(log_hz1, torch.ones_like(y).bool(), y.float())}\")\n",
    "print(f\"Cindex (momentum) = {cindex2(log_hz2, torch.ones_like(y).bool(), y.float())}\")\n",
    "# H1: cindex_momentum > cindex_regular, H0: same\n",
    "print(f\"Compare (p-value) = {cindex2.compare(cindex1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsurv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
