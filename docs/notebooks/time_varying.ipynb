{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing time-varying covariates\n",
    "\n",
    "In this notebook, we analyse a simulated dataset with time-varying covariates and survival outcomes. `TorchSurv` is used to train a model that predicts relative risk of subjects based on covariates observed over time. We will attempt to thoroughly explain the necessary elements to understand our implementation, but for a detailed read on time-varying survival models refer to Chapter 6 of [Dynamic Regression Models for Survival Data](https://link.springer.com/book/10.1007/0-387-33960-4). \n",
    "\n",
    "### Dependencies\n",
    "\n",
    "To run this notebook, dependencies must be installed. the recommended method is to use our developpment conda environment (**preffered**). Instruction can be found [here](https://opensource.nibr.com/torchsurv/devnotes.html#set-up-a-development-environment-via-conda) to install all optional dependancies. The other method is to install only required packages using the command line below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install only required packages (optional)\n",
    "# %pip install lifelines\n",
    "# %pip install matplotlib\n",
    "# %pip install sklearn\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Our package\n",
    "#from torchsurv.loss.time_varying import neg_partial_log_likelihood2\n",
    "\n",
    "# PyTorch boilerplate - see https://github.com/Novartis/torchsurv/blob/main/docs/notebooks/helpers_introduction.py\n",
    "from helpers_introduction import Custom_dataset, plot_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a dataset\n",
    "\n",
    "We will simulate a dataset of 100 subjects with 6 follow up times where a covariate is observed. The covariates will change over time slightly but will be generated from one random variable per subject so that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters\n",
    "sample_size = 100  #number of subjects to generate\n",
    "obs_time = 6 #number of observations over time for each subject\n",
    "\n",
    "# create random variables following a normal distribution N(1,1) for each subject \n",
    "mean = 1\n",
    "standard_dev = 1\n",
    "random_vars = torch.randn(sample_size)*standard_dev + mean\n",
    "\n",
    "# using the random variables from above, we create a set of covariates for each subject \n",
    "t = torch.linspace(0, 2*math.pi, 6)  # Generating 6 equidistant time points from 0 to 2*pi\n",
    "\n",
    "# Creating the matrix\n",
    "sample_size = 100  #number of subjects to generate\n",
    "matrix = torch.zeros(sample_size, 6)\n",
    "\n",
    "# Filling the matrix with sin values\n",
    "for i in range(6):\n",
    "    matrix[:, i] = torch.sin(t[i])\n",
    "\n",
    "# Multiplying with a vector of random variables\n",
    "sample_size = 100  #number of subjects to generate\n",
    "random_vars = torch.randn(sample_size)\n",
    "result = torch.matmul(matrix.T, random_vars.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random boolean events\n",
    "events = random_vars > 0.5\n",
    "print(events)  # tensor([ True, False,  True,  True, False, False,  True, False])\n",
    "\n",
    "# make random positive time to event\n",
    "time =  random_vars * 100\n",
    "print(time)  # tensor([32.8563, 38.3207, 24.6015, 72.2986, 19.9004, 65.2180, 73.2083, 21.2663])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing partial log likelihood for time-varying covariates\n",
    "\n",
    "Let $T*_i$ be the be the failure time of interest for subject $i$ and $C$ be the censoring time. Let $T_i = min(T*, C)$. We use $\\delta_i$ to denote whether $T*_i$ was observed. We will use $Z(t)$ to denote the value of of covariate $Z$ and time $t$. Let $t_k$ for $k \\in \\{1, \\dots, K\\} denote the time points at which the covariates are observed. For the moment, we assume that all subjects have been observed on the same time grid. $R_k$ is the set of individuals who are at risk at $t_k$.\n",
    "\n",
    "\n",
    "Consider a network that outputs a vector $\\theta$ for each observed covariate $Z(t_k)$, which can be denoted as $\\theta(t_k)$. The vector of these values can be written to be $\\theta_K$. Similarly, $Z_K$ can be the vector of the covariate history up until time K. \n",
    "\n",
    "The log likelihood in terms of $\\theta(t_k)$ can be written as follows.\n",
    "\n",
    "$$ l(\\theta) = \\sum_{i=1}^n \\delta_i \\Big ( \\frac{\\sum_{j \\in R_i} exp(\\theta_K)Z_K Z_K^T}{\\sum_{j \\in R_i} exp(\\theta_K)}-\\frac{[\\sum_{j \\in R_i} exp(\\theta_K)Z_K][\\sum_{j \\in R_i} exp(\\theta_K)Z_K]^T}{\\sum_{j \\in R_i} exp(\\theta_K)}\\Big)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_partial_log_likelihood(\n",
    "    log_hz: torch.Tensor, #nx1 vector\n",
    "    event: torch.Tensor, #n vector (i think)\n",
    "    time: torch.Tensor, #n vector (i think)\n",
    "    covariates: torch.Tensor, #nxp vector, p number of params\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    # sort data by time-to-event or censoring\n",
    "    time_sorted, idx = torch.sort(time)\n",
    "    log_hz_sorted = log_hz[idx]\n",
    "    event_sorted = event[idx]\n",
    "\n",
    "    exp_log_hz = torch.exp(log_hz_sorted)\n",
    "    #need to sort the covariate here as well \n",
    "    #sort covariates so that the rows match the ordering\n",
    "    covariates_sorted = covariates[idx, :]\n",
    "\n",
    "    #the left hand side (HS) of the equation\n",
    "    #below is Z_k Z_k^T - i think it should be a vector matrix dim nxn\n",
    "    covariate_inner_product = torch.matmul(covariates_sorted, covariates_sorted.T)\n",
    "    \n",
    "    #pointwise multiplication of vectors to get the nominator of left HS\n",
    "    #outcome in a vector of length n\n",
    "    # Ends up being (1, n)\n",
    "    log_nominator_left = torch.matmul(exp_log_hz.T, covariate_inner_product)\n",
    "\n",
    "    #right hand size of the equation\n",
    "    #formulate the brackets \\sum exp(theta)Z_k\n",
    "    bracket = torch.mul(exp_log_hz, covariates_sorted)\n",
    "    nominator_right = torch.matmul(bracket, bracket.T) #nxn matrix\n",
    "    ###not sure if the next line is this\n",
    "    #log_nominator_right = torch.sum(nominator_right, dim=0).unsqueeze(0)\n",
    "    ### or this\n",
    "    log_nominator_right = nominator_right[0,].unsqueeze(0)\n",
    "    #the denominator is the same on both sides\n",
    "    log_denominator = torch.logcumsumexp(log_hz_sorted.flip(0), dim=0).flip(0) #dim=0 sums over the oth dimension\n",
    "    partial_log_likelihood = torch.div(log_nominator_left - log_nominator_right, log_denominator) # (n, n)\n",
    "    return (partial_log_likelihood)[event_sorted]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the old dataset for dimensions sake\n",
    "\n",
    "using the data from the introduction notebook just to make sure dimensions work, this is not correct implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GBSG2 dataset\n",
    "df = lifelines.datasets.load_gbsg2()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant parameters accross models\n",
    "# Detect available accelerator; Downgrade batch size if only CPU available\n",
    "if any([torch.cuda.is_available(), torch.backends.mps.is_available()]):\n",
    "    print(\"CUDA-enabled GPU/TPU is available.\")\n",
    "    BATCH_SIZE = 128  # batch size for training\n",
    "else:\n",
    "    print(\"No CUDA-enabled GPU found, using CPU.\")\n",
    "    BATCH_SIZE = 32  # batch size for training\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(df, columns=[\"horTh\", \"menostat\", \"tgrade\"]).astype(\"float\")\n",
    "df_onehot.drop(\n",
    "    [\"horTh_no\", \"menostat_Post\", \"tgrade_I\"],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "df_onehot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_onehot, test_size=0.3)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.3)\n",
    "print(\n",
    "    f\"(Sample size) Training:{len(df_train)} | Validation:{len(df_val)} |Testing:{len(df_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "dataloader_train = DataLoader(\n",
    "    Custom_dataset(df_train), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    Custom_dataset(df_val), batch_size=len(df_val), shuffle=False\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    Custom_dataset(df_test), batch_size=len(df_test), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm1d(num_features),  # Batch normalization\n",
    "    torch.nn.Linear(num_features, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(32, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(64, 1),  # Estimating log hazards for Cox models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for testing the loss function\n",
    "x_test, (test_event, test_time) = next(iter(dataloader_train))\n",
    "\n",
    "log_hz = cox_model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3927, 1.5773, 0.0192, 0.1983])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('x_test', x_test.shape)\n",
    "print('events', test_event.shape)\n",
    "print('times', test_time.shape)\n",
    "\n",
    "time_sorted, idx = torch.sort(time)\n",
    "log_hz_sorted = log_hz[idx]\n",
    "event_sorted = event[idx]\n",
    "time_unique = torch.unique(time_sorted)\n",
    "print('')\n",
    "print(\"time_sorted\", time_sorted.shape)\n",
    "print('log_hz_sorted', log_hz_sorted.shape)\n",
    "print('event_sorted', event_sorted.shape)\n",
    "print(\"time_unique\", time_unique.shape)\n",
    "\n",
    "print('-'*30)\n",
    "cov_fake = torch.clone(x_test)\n",
    "print('covariates', cov_fake.shape)\n",
    "covariates_sorted = cov_fake[idx, :]\n",
    "covariate_inner_product = torch.matmul(covariates_sorted, covariates_sorted.T)\n",
    "print('cov_inner', covariate_inner_product.shape)\n",
    "log_nominator_left = torch.matmul(log_hz_sorted.T, covariate_inner_product)\n",
    "print('log_nom_left', log_nominator_left.shape)\n",
    "bracket = torch.mul(log_hz_sorted, covariates_sorted)\n",
    "print('bracket', bracket.shape)\n",
    "log_nominator_right = torch.matmul(bracket, bracket.T)\n",
    "print('log_nom_right', log_nominator_right.shape)\n",
    "sum_nominator_right = log_nominator_right[0,].unsqueeze(0)\n",
    "print('sum_nom', sum_nominator_right.shape)\n",
    "log_denominator = torch.logcumsumexp(log_hz_sorted.flip(0), dim=0).flip(0).T\n",
    "print('log_denom', log_denominator.shape)\n",
    "last_bit = torch.div(log_nominator_left - sum_nominator_right, log_denominator)\n",
    "print('last_bit', last_bit.shape)\n",
    "last_bit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Example from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsurv.loss import cox\n",
    "from torchsurv.metrics.cindex import ConcordanceIndex\n",
    "\n",
    "# Parameters\n",
    "input_size = 10\n",
    "output_size = 1\n",
    "num_layers = 2\n",
    "seq_length = 5\n",
    "batch_size = 8\n",
    "\n",
    "# make random boolean events\n",
    "events = torch.rand(batch_size) > 0.5\n",
    "print(events)  # tensor([ True, False,  True,  True, False, False,  True, False])\n",
    "\n",
    "# make random positive time to event\n",
    "time = torch.rand(batch_size) * 100\n",
    "print(time)  # tensor([32.8563, 38.3207, 24.6015, 72.2986, 19.9004, 65.2180, 73.2083, 21.2663])\n",
    "\n",
    "# Create simple RNN model\n",
    "rnn = torch.nn.RNN(input_size, output_size, num_layers)\n",
    "inputs = torch.randn(seq_length, batch_size, input_size)\n",
    "h0 = torch.randn(num_layers, batch_size, output_size)\n",
    "\n",
    "# Forward pass time series input\n",
    "outputs, _ = rnn(inputs, h0)\n",
    "estimates = outputs[-1]  # Keep only last predictions, many to one approach\n",
    "print(estimates.size())  # torch.Size([8, 1])\n",
    "print(f\"Estimate shape for {batch_size} samples = {estimates.size()}\")  # Estimate shape for 8 samples = torch.Size([8, 1])\n",
    "\n",
    "\n",
    "loss = cox.neg_partial_log_likelihood(estimates, events, time)\n",
    "print(f\"loss = {loss}, has gradient = {loss.requires_grad}\")  # loss = 1.0389232635498047, has gradient = True\n",
    "\n",
    "cindex = ConcordanceIndex()\n",
    "print(f\"c-index = {cindex(estimates, events, time)}\")  # c-index = 0.20000000298023224"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
